{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Setup inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1- Instalar librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librerías\n",
    "#!pip install openai\n",
    "#!pip install spacy\n",
    "#!pip install tenacity\n",
    "#!pip install python-dotenv\n",
    "#!spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.- Cargar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import difflib\n",
    "import spacy\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.- OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar secretos y configuración desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar la clave de la API de OpenAI\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "print(\"OpenAI API key: {}\".format(openai.api_key[:5] + '...' + openai.api_key[-5:]))\n",
    "\n",
    "# Nombres de los modelos\n",
    "gpt35_model = os.getenv(\"OPENAI_GPT35_MODEL\")\n",
    "gpt35_16k_model = os.getenv(\"OPENAI_GPT35_16K_MODEL\")\n",
    "gpt4_model = os.getenv(\"OPENAI_GPT4_MODEL\")\n",
    "print(\"GPT-3.5-Turbo model: {}\".format(gpt35_model))\n",
    "print(\"GPT-3.5-Turbo-16k model: {}\".format(gpt35_16k_model))\n",
    "print(\"GPT-4 model: {}\".format(gpt4_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.- Importar clase Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.tools import Tool, Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.- Definir funciones útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(3))\n",
    "def generate_text(prompt, model=gpt35_model, messages=[], max_tokens=200, temperature=1.0, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0, stop=None):\n",
    "    _messages = []\n",
    "    _messages.extend(messages)\n",
    "    _messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=_messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        stop=stop\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cities(text):\n",
    "    nlp = spacy.load(\"es_core_news_sm\")  # Carga el modelo de procesamiento de texto en español\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Encuentra nombres de ciudades en el texto\n",
    "    cities = [entity.text for entity in doc.ents if entity.label_ == \"LOC\"]\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Suma de números o concatenación de strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumar(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "def concatenar_strings(s1: str, s2: str) -> str:\n",
    "    return s1 + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Instanciar funciones como Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumar_tool = Tool(\n",
    "    name=\"Sumar números\",\n",
    "    func=sumar,\n",
    "    description=\"Esta función recibe dos números enteros como entrada y devuelve la suma de estos dos números.\",\n",
    "    arguments=[\n",
    "        Parameter(name=\"a\", description=\"Primer número\", type=int, required=True),\n",
    "        Parameter(name=\"b\", description=\"Segundo número\", type=int, required=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "concatenar_tool = Tool(\n",
    "    name=\"Concatenar strings\",\n",
    "    func=concatenar_strings,\n",
    "    description=\"Esta función toma dos palabras como entrada y las combina en una sola cadena de texto, sin agregar espacios ni caracteres adicionales.\",\n",
    "    arguments=[\n",
    "        Parameter(name=\"s1\", description=\"Primera cadena\", type=str, required=True),\n",
    "        Parameter(name=\"s2\", description=\"Segunda cadena\", type=str, required=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Definir lista de tools\n",
    "tools1 = [sumar_tool, concatenar_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Función de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_decision1(user_input: str, tools: list[Tool]) -> Tool:\n",
    "    # Basado en el input del usuario, determina qué herramienta usar.\n",
    "    # (Aquí estamos simplificando y usando solo las descripciones, pero en la realidad podría ser más complejo)\n",
    "    best_match = None\n",
    "    highest_similarity = 0\n",
    "    for tool in tools:\n",
    "        similarity = difflib.SequenceMatcher(None, user_input, tool.description).ratio()  # Función hipotética que compara similitud.\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            best_match = tool\n",
    "            \n",
    "    if best_match == sumar_tool:\n",
    "        numbers = [int(word) for word in user_input.split() if word.isdigit()]\n",
    "        return best_match, {\"a\": numbers[0], \"b\": numbers[1]}\n",
    "    else:\n",
    "        # Supongamos que las cadenas a concatenar están entre comillas\n",
    "        strings = [word.strip('\"') for word in user_input.split() if word.startswith('\"') and word.endswith('\"')]\n",
    "        return concatenar_tool, {\"s1\": strings[0], \"s2\": strings[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Ejemplos de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sumar números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = \"Sumar los números 5 y 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool1, args1 = LLM_decision1(input, tools)\n",
    "display(HTML(f\"<h5>Se ha seleccionado la función: {tool1.name}, sus argumentos son: {' y '.join(map(str, args1.values()))} </h5>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q1 = tool1.execute(**args1)\n",
    "display(HTML(f\"<h5>Debería imprimir 12. El resultado obtenido es: {result_q1} </h5>\"))  # Debería imprimir 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sumar strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = 'Genera un texto con estas palabras: \"hola\" y \"mundo\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2, args2 = LLM_decision1(question2, tools)\n",
    "display(HTML(f\"<h5>Se ha seleccionado la función: {tool2.name}, sus argumentos son: {' y '.join(map(str, args2.values()))} </h5>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q2 = tool2.execute(**args2)\n",
    "display(HTML(f\"<h5>Debería imprimir holamundo. El resultado obtenido es: {result_q2} </h5>\"))  # Debería imprimir holamundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tiempo meteorológico o tiempo de viaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from llm import generate_text\n",
    "\n",
    "# Una función que consulta una API meteorológica\n",
    "def consultar_clima(ciudad: str, fecha: int) -> dict:\n",
    "    prompt = f\"Cómo estará el clima en {ciudad} el {fecha}\"\n",
    "    response = generate_text(prompt, model=gpt4_model)\n",
    "    return response\n",
    "\n",
    "def tiempo_de_viaje(ciudad1: str, ciudad2: str) -> str:\n",
    "    prompt = f\"Cúal es el tiempo de viajes desde {ciudad1} a {ciudad2}\"\n",
    "    response = generate_text(prompt, model=gpt4_model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Instanciar funciones como Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea instancias de las funciones como objetos Tool\n",
    "clima_tool = Tool(\n",
    "    name = \"Consultar clima\", \n",
    "    func = consultar_clima, \n",
    "    description = \"Esta función proporciona información simulada sobre las condiciones climáticas en una ciudad específica en una fecha determinada. Es útil para obtener una idea general del clima en un lugar en un momento particular y puede ser utilizado para planificar actividades al aire libre.\",\n",
    "    arguments = [\n",
    "        Parameter(\"ciudad\", str, \"Nombre de la ciudad\", True), \n",
    "        Parameter(\"fecha\", datetime, \"Fecha de consulta\", True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "viaje_tool = Tool(\n",
    "    name = \"Tiempo de viaje\", \n",
    "    func = tiempo_de_viaje, \n",
    "    description = \"Esta función calcula el tiempo estimado de viaje entre dos ciudades. Utiliza datos simulados para proporcionar una estimación del tiempo que tomará llegar de una ciudad de origen a una ciudad de destino. Esta estimación puede ser útil para planificar tus viajes y actividades.\", \n",
    "    arguments = [\n",
    "        Parameter(\"ciudad1\", str, \"Ciudad de origen\", True), \n",
    "        Parameter(\"ciudad2\", str, \"Ciudad de destino\", True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools2 = [clima_tool, viaje_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Función de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_decision2(user_input: str, tools: list[Tool]) -> Tool:\n",
    "    # Basado en el input del usuario, determina qué herramienta usar.\n",
    "    # (Aquí estamos simplificando y usando solo las descripciones, pero en la realidad podría ser más complejo)\n",
    "    best_match = None\n",
    "    highest_similarity = 0\n",
    "    for tool in tools:\n",
    "        similarity = difflib.SequenceMatcher(None, user_input, tool.description).ratio()  # Función hipotética que compara similitud.\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            best_match = tool\n",
    "    if best_match == clima_tool:\n",
    "        cities = identify_cities(user_input)\n",
    "        date = parser.parse(user_input, fuzzy_with_tokens=True)\n",
    "        return best_match, {\"ciudad\": cities[0], \"fecha\": date[0]}\n",
    "    else:\n",
    "        cities = identify_cities(user_input)\n",
    "        return best_match, {\"ciudad1\": cities[0], \"ciudad2\": cities[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Ejemplos de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Tiempo meteorológico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input3 = \"Tiempo para el miércoles 25 de octubre en Barcelona\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la función de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool3, args3 = LLM_decision(input3, tools2)\n",
    "display(HTML(f\"<h5>Se ha seleccionado la función: {tool3.name}, sus argumentos son: {' y '.join(map(str, args3.values()))} </h5>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta la función y se verifica el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q3 = tool3.execute(args3)\n",
    "display(HTML(f\"<h5>Debería imprimir 12. El resultado obtenido es: {result_q3} </h5>\"))  # Debería imprimir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tiempo de viaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input4 = 'Tiempo de viaje de Madrid a Barcelona'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la función de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool4, args4 = LLM_decision(input4, tools)\n",
    "display(HTML(f\"<h5>Se ha seleccionado la función: {tool4.name}, sus argumentos son: {' y '.join(map(str, args4.values()))} </h5>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta la función y se verifica el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q4 = tool4.execute(**args4)\n",
    "display(HTML(f\"<h5>Debería imprimir holamundo. El resultado obtenido es: {result_q2} </h5>\"))  # Debería imprimir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
